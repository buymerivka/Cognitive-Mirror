{
  "best_global_step": 2220,
  "best_metric": 0.41164880990982056,
  "best_model_checkpoint": "./results/checkpoint-2220",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 2220,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06756756756756757,
      "grad_norm": 2.040379047393799,
      "learning_rate": 4.88963963963964e-05,
      "loss": 0.6825,
      "step": 50
    },
    {
      "epoch": 0.13513513513513514,
      "grad_norm": 3.0968542098999023,
      "learning_rate": 4.7770270270270274e-05,
      "loss": 0.575,
      "step": 100
    },
    {
      "epoch": 0.20270270270270271,
      "grad_norm": 2.1565120220184326,
      "learning_rate": 4.664414414414415e-05,
      "loss": 0.5893,
      "step": 150
    },
    {
      "epoch": 0.2702702702702703,
      "grad_norm": 1.5441837310791016,
      "learning_rate": 4.551801801801802e-05,
      "loss": 0.543,
      "step": 200
    },
    {
      "epoch": 0.33783783783783783,
      "grad_norm": 1.0493754148483276,
      "learning_rate": 4.439189189189189e-05,
      "loss": 0.5272,
      "step": 250
    },
    {
      "epoch": 0.40540540540540543,
      "grad_norm": 1.9706536531448364,
      "learning_rate": 4.326576576576577e-05,
      "loss": 0.5755,
      "step": 300
    },
    {
      "epoch": 0.47297297297297297,
      "grad_norm": 5.281517505645752,
      "learning_rate": 4.2139639639639646e-05,
      "loss": 0.5351,
      "step": 350
    },
    {
      "epoch": 0.5405405405405406,
      "grad_norm": 1.8702671527862549,
      "learning_rate": 4.101351351351351e-05,
      "loss": 0.5426,
      "step": 400
    },
    {
      "epoch": 0.6081081081081081,
      "grad_norm": 1.9577007293701172,
      "learning_rate": 3.9887387387387386e-05,
      "loss": 0.4745,
      "step": 450
    },
    {
      "epoch": 0.6756756756756757,
      "grad_norm": 1.2264312505722046,
      "learning_rate": 3.876126126126126e-05,
      "loss": 0.4835,
      "step": 500
    },
    {
      "epoch": 0.7432432432432432,
      "grad_norm": 2.275123119354248,
      "learning_rate": 3.763513513513513e-05,
      "loss": 0.5231,
      "step": 550
    },
    {
      "epoch": 0.8108108108108109,
      "grad_norm": 13.49829387664795,
      "learning_rate": 3.650900900900901e-05,
      "loss": 0.4651,
      "step": 600
    },
    {
      "epoch": 0.8783783783783784,
      "grad_norm": 2.8222522735595703,
      "learning_rate": 3.5382882882882885e-05,
      "loss": 0.4723,
      "step": 650
    },
    {
      "epoch": 0.9459459459459459,
      "grad_norm": 4.161720275878906,
      "learning_rate": 3.425675675675676e-05,
      "loss": 0.521,
      "step": 700
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.9258133587652962,
      "eval_loss": 0.4389019012451172,
      "eval_runtime": 308.9011,
      "eval_samples_per_second": 19.165,
      "eval_steps_per_second": 0.599,
      "step": 740
    },
    {
      "epoch": 1.0135135135135136,
      "grad_norm": 5.524815559387207,
      "learning_rate": 3.313063063063063e-05,
      "loss": 0.4828,
      "step": 750
    },
    {
      "epoch": 1.0810810810810811,
      "grad_norm": 9.203178405761719,
      "learning_rate": 3.2004504504504505e-05,
      "loss": 0.4488,
      "step": 800
    },
    {
      "epoch": 1.1486486486486487,
      "grad_norm": 6.667306423187256,
      "learning_rate": 3.087837837837838e-05,
      "loss": 0.4437,
      "step": 850
    },
    {
      "epoch": 1.2162162162162162,
      "grad_norm": 3.4088292121887207,
      "learning_rate": 2.9752252252252255e-05,
      "loss": 0.4177,
      "step": 900
    },
    {
      "epoch": 1.2837837837837838,
      "grad_norm": 2.135659694671631,
      "learning_rate": 2.8626126126126128e-05,
      "loss": 0.3878,
      "step": 950
    },
    {
      "epoch": 1.3513513513513513,
      "grad_norm": 5.028954982757568,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 0.4311,
      "step": 1000
    },
    {
      "epoch": 1.4189189189189189,
      "grad_norm": 5.705691814422607,
      "learning_rate": 2.6373873873873878e-05,
      "loss": 0.4337,
      "step": 1050
    },
    {
      "epoch": 1.4864864864864864,
      "grad_norm": 42.037837982177734,
      "learning_rate": 2.5247747747747747e-05,
      "loss": 0.4221,
      "step": 1100
    },
    {
      "epoch": 1.554054054054054,
      "grad_norm": 5.454813003540039,
      "learning_rate": 2.4121621621621624e-05,
      "loss": 0.3937,
      "step": 1150
    },
    {
      "epoch": 1.6216216216216215,
      "grad_norm": 7.098505020141602,
      "learning_rate": 2.2995495495495497e-05,
      "loss": 0.3873,
      "step": 1200
    },
    {
      "epoch": 1.689189189189189,
      "grad_norm": 3.733295202255249,
      "learning_rate": 2.186936936936937e-05,
      "loss": 0.4319,
      "step": 1250
    },
    {
      "epoch": 1.7567567567567568,
      "grad_norm": 3.392343044281006,
      "learning_rate": 2.0743243243243243e-05,
      "loss": 0.4018,
      "step": 1300
    },
    {
      "epoch": 1.8243243243243243,
      "grad_norm": 4.655642032623291,
      "learning_rate": 1.9617117117117117e-05,
      "loss": 0.4273,
      "step": 1350
    },
    {
      "epoch": 1.8918918918918919,
      "grad_norm": 6.313272476196289,
      "learning_rate": 1.8490990990990993e-05,
      "loss": 0.4614,
      "step": 1400
    },
    {
      "epoch": 1.9594594594594594,
      "grad_norm": 5.616125583648682,
      "learning_rate": 1.7364864864864866e-05,
      "loss": 0.418,
      "step": 1450
    },
    {
      "epoch": 2.0,
      "eval_f1": 0.9310820646737732,
      "eval_loss": 0.41365495324134827,
      "eval_runtime": 156.6011,
      "eval_samples_per_second": 37.803,
      "eval_steps_per_second": 1.181,
      "step": 1480
    },
    {
      "epoch": 2.027027027027027,
      "grad_norm": 3.180939197540283,
      "learning_rate": 1.623873873873874e-05,
      "loss": 0.394,
      "step": 1500
    },
    {
      "epoch": 2.0945945945945947,
      "grad_norm": 6.460625171661377,
      "learning_rate": 1.5112612612612614e-05,
      "loss": 0.3847,
      "step": 1550
    },
    {
      "epoch": 2.1621621621621623,
      "grad_norm": 3.9037652015686035,
      "learning_rate": 1.3986486486486486e-05,
      "loss": 0.401,
      "step": 1600
    },
    {
      "epoch": 2.22972972972973,
      "grad_norm": 5.614672660827637,
      "learning_rate": 1.286036036036036e-05,
      "loss": 0.3957,
      "step": 1650
    },
    {
      "epoch": 2.2972972972972974,
      "grad_norm": 11.982675552368164,
      "learning_rate": 1.1734234234234234e-05,
      "loss": 0.3672,
      "step": 1700
    },
    {
      "epoch": 2.364864864864865,
      "grad_norm": 5.3616743087768555,
      "learning_rate": 1.0608108108108109e-05,
      "loss": 0.3773,
      "step": 1750
    },
    {
      "epoch": 2.4324324324324325,
      "grad_norm": 3.014174699783325,
      "learning_rate": 9.481981981981982e-06,
      "loss": 0.3733,
      "step": 1800
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.3371405601501465,
      "learning_rate": 8.355855855855855e-06,
      "loss": 0.2979,
      "step": 1850
    },
    {
      "epoch": 2.5675675675675675,
      "grad_norm": 3.763906240463257,
      "learning_rate": 7.22972972972973e-06,
      "loss": 0.365,
      "step": 1900
    },
    {
      "epoch": 2.635135135135135,
      "grad_norm": 6.04865837097168,
      "learning_rate": 6.103603603603604e-06,
      "loss": 0.3693,
      "step": 1950
    },
    {
      "epoch": 2.7027027027027026,
      "grad_norm": 4.599413871765137,
      "learning_rate": 4.977477477477477e-06,
      "loss": 0.3629,
      "step": 2000
    },
    {
      "epoch": 2.77027027027027,
      "grad_norm": 2.9778406620025635,
      "learning_rate": 3.851351351351352e-06,
      "loss": 0.3542,
      "step": 2050
    },
    {
      "epoch": 2.8378378378378377,
      "grad_norm": 9.933634757995605,
      "learning_rate": 2.7252252252252253e-06,
      "loss": 0.3201,
      "step": 2100
    },
    {
      "epoch": 2.9054054054054053,
      "grad_norm": 1.5608073472976685,
      "learning_rate": 1.5990990990990991e-06,
      "loss": 0.3673,
      "step": 2150
    },
    {
      "epoch": 2.972972972972973,
      "grad_norm": 4.479626655578613,
      "learning_rate": 4.72972972972973e-07,
      "loss": 0.3093,
      "step": 2200
    },
    {
      "epoch": 3.0,
      "eval_f1": 0.9331589246887082,
      "eval_loss": 0.41164880990982056,
      "eval_runtime": 155.1604,
      "eval_samples_per_second": 38.154,
      "eval_steps_per_second": 1.192,
      "step": 2220
    }
  ],
  "logging_steps": 50,
  "max_steps": 2220,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4672188855733248.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
